{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data  status type message  \\\n",
      "0  {'mal_id': 1, 'url': 'https://myanimelist.net/...     NaN  NaN     NaN   \n",
      "1  {'mal_id': 5, 'url': 'https://myanimelist.net/...     NaN  NaN     NaN   \n",
      "2  {'mal_id': 6, 'url': 'https://myanimelist.net/...     NaN  NaN     NaN   \n",
      "3  {'mal_id': 7, 'url': 'https://myanimelist.net/...     NaN  NaN     NaN   \n",
      "4  {'mal_id': 8, 'url': 'https://myanimelist.net/...     NaN  NaN     NaN   \n",
      "\n",
      "  error  \n",
      "0   NaN  \n",
      "1   NaN  \n",
      "2   NaN  \n",
      "3   NaN  \n",
      "4   NaN  \n",
      "Total de registros combinados: 27530\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Cargar los archivos JSON\n",
    "json1_path = 'D:/DataScience/TFB/Data/all_anime_data1.json'\n",
    "json2_path = 'D:/DataScience/TFB/Data/all_anime_data2.json'\n",
    "\n",
    "# Leer el primer archivo JSON\n",
    "with open(json1_path, 'r', encoding='utf-8') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "# Leer el segundo archivo JSON\n",
    "with open(json2_path, 'r', encoding='utf-8') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "# Combinar los datos (asumiendo que son listas de diccionarios)\n",
    "combined_data = data1 + data2\n",
    "\n",
    "# Crear el DataFrame\n",
    "df = pd.DataFrame(combined_data)\n",
    "\n",
    "# Ahora puedes proceder con la limpieza de datos\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df.head())\n",
    "print(f\"Total de registros combinados: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(df['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mal_id                                                url approved  \\\n",
      "0     1.0       https://myanimelist.net/anime/1/Cowboy_Bebop     True   \n",
      "1     5.0  https://myanimelist.net/anime/5/Cowboy_Bebop__...     True   \n",
      "2     6.0             https://myanimelist.net/anime/6/Trigun     True   \n",
      "3     7.0  https://myanimelist.net/anime/7/Witch_Hunter_R...     True   \n",
      "4     8.0     https://myanimelist.net/anime/8/Bouken_Ou_Beet     True   \n",
      "\n",
      "                                              titles  \\\n",
      "0  [{'type': 'Default', 'title': 'Cowboy Bebop'},...   \n",
      "1  [{'type': 'Default', 'title': 'Cowboy Bebop: T...   \n",
      "2  [{'type': 'Default', 'title': 'Trigun'}, {'typ...   \n",
      "3  [{'type': 'Default', 'title': 'Witch Hunter Ro...   \n",
      "4  [{'type': 'Default', 'title': 'Bouken Ou Beet'...   \n",
      "\n",
      "                             title            title_english  \\\n",
      "0                     Cowboy Bebop             Cowboy Bebop   \n",
      "1  Cowboy Bebop: Tengoku no Tobira  Cowboy Bebop: The Movie   \n",
      "2                           Trigun                   Trigun   \n",
      "3               Witch Hunter Robin       Witch Hunter Robin   \n",
      "4                   Bouken Ou Beet   Beet the Vandel Buster   \n",
      "\n",
      "                     title_japanese  \\\n",
      "0                         „Ç´„Ç¶„Éú„Éº„Ç§„Éì„Éê„ÉÉ„Éó   \n",
      "1                    „Ç´„Ç¶„Éú„Éº„Ç§„Éì„Éê„ÉÉ„Éó Â§©ÂõΩ„ÅÆÊââ   \n",
      "2                             „Éà„É©„Ç§„Ç¨„É≥   \n",
      "3  Witch Hunter ROBIN („Ç¶„Ç§„ÉÉ„ÉÅ„Éè„É≥„Çø„Éº„É≠„Éì„É≥)   \n",
      "4                            ÂÜíÈô∫Áéã„Éì„Ç£„Éà   \n",
      "\n",
      "                              title_synonyms   type    source  episodes  \\\n",
      "0                                         []     TV  Original      26.0   \n",
      "1  [Cowboy Bebop: Knockin' on Heaven's Door]  Movie  Original       1.0   \n",
      "2                                         []     TV     Manga      26.0   \n",
      "3                                      [WHR]     TV  Original      26.0   \n",
      "4                      [Adventure King Beet]     TV     Manga      52.0   \n",
      "\n",
      "            status airing       duration                          rating  \\\n",
      "0  Finished Airing  False  24 min per ep  R - 17+ (violence & profanity)   \n",
      "1  Finished Airing  False    1 hr 55 min  R - 17+ (violence & profanity)   \n",
      "2  Finished Airing  False  24 min per ep       PG-13 - Teens 13 or older   \n",
      "3  Finished Airing  False  25 min per ep       PG-13 - Teens 13 or older   \n",
      "4  Finished Airing  False  23 min per ep                   PG - Children   \n",
      "\n",
      "   score  scored_by    rank  popularity    members  favorites  \\\n",
      "0   8.75  1008302.0    47.0        42.0  1951449.0    85799.0   \n",
      "1   8.38   223434.0   214.0       637.0   393928.0     1686.0   \n",
      "2   8.22   385997.0   367.0       260.0   795496.0    16696.0   \n",
      "3   7.24    45115.0  3174.0      1926.0   122032.0      664.0   \n",
      "4   6.93     6937.0  4698.0      5581.0    16184.0       16.0   \n",
      "\n",
      "                                            synopsis  \\\n",
      "0  Crime is timeless. By the year 2071, humanity ...   \n",
      "1  Another day, another bounty‚Äîsuch is the life o...   \n",
      "2  Vash the Stampede is the man with a $$60,000,0...   \n",
      "3  Though hidden away from the general public, Wi...   \n",
      "4  It is the dark century and the people are suff...   \n",
      "\n",
      "                                          background  season    year  \\\n",
      "0  When Cowboy Bebop first aired in spring of 199...  spring  1998.0   \n",
      "1                                                       None     NaN   \n",
      "2  The Japanese release by Victor Entertainment h...  spring  1998.0   \n",
      "3                                                     summer  2002.0   \n",
      "4                                                       fall  2004.0   \n",
      "\n",
      "                                           producers  \\\n",
      "0  [{'mal_id': 23, 'type': 'anime', 'name': 'Band...   \n",
      "1  [{'mal_id': 14, 'type': 'anime', 'name': 'Sunr...   \n",
      "2  [{'mal_id': 123, 'type': 'anime', 'name': 'Vic...   \n",
      "3  [{'mal_id': 23, 'type': 'anime', 'name': 'Band...   \n",
      "4  [{'mal_id': 16, 'type': 'anime', 'name': 'TV T...   \n",
      "\n",
      "                                           licensors  \\\n",
      "0  [{'mal_id': 102, 'type': 'anime', 'name': 'Fun...   \n",
      "1  [{'mal_id': 15, 'type': 'anime', 'name': 'Sony...   \n",
      "2  [{'mal_id': 102, 'type': 'anime', 'name': 'Fun...   \n",
      "3  [{'mal_id': 102, 'type': 'anime', 'name': 'Fun...   \n",
      "4  [{'mal_id': 2262, 'type': 'anime', 'name': 'Il...   \n",
      "\n",
      "                                             studios  \\\n",
      "0  [{'mal_id': 14, 'type': 'anime', 'name': 'Sunr...   \n",
      "1  [{'mal_id': 4, 'type': 'anime', 'name': 'Bones...   \n",
      "2  [{'mal_id': 11, 'type': 'anime', 'name': 'Madh...   \n",
      "3  [{'mal_id': 14, 'type': 'anime', 'name': 'Sunr...   \n",
      "4  [{'mal_id': 18, 'type': 'anime', 'name': 'Toei...   \n",
      "\n",
      "                                              genres explicit_genres  \\\n",
      "0  [{'mal_id': 1, 'type': 'anime', 'name': 'Actio...              []   \n",
      "1  [{'mal_id': 1, 'type': 'anime', 'name': 'Actio...              []   \n",
      "2  [{'mal_id': 1, 'type': 'anime', 'name': 'Actio...              []   \n",
      "3  [{'mal_id': 1, 'type': 'anime', 'name': 'Actio...              []   \n",
      "4  [{'mal_id': 1, 'type': 'anime', 'name': 'Actio...              []   \n",
      "\n",
      "                                              themes  \\\n",
      "0  [{'mal_id': 50, 'type': 'anime', 'name': 'Adul...   \n",
      "1  [{'mal_id': 50, 'type': 'anime', 'name': 'Adul...   \n",
      "2  [{'mal_id': 50, 'type': 'anime', 'name': 'Adul...   \n",
      "3  [{'mal_id': 39, 'type': 'anime', 'name': 'Dete...   \n",
      "4                                                 []   \n",
      "\n",
      "                                        demographics  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2  [{'mal_id': 27, 'type': 'anime', 'name': 'Shou...   \n",
      "3                                                 []   \n",
      "4  [{'mal_id': 27, 'type': 'anime', 'name': 'Shou...   \n",
      "\n",
      "                                images.jpg.image_url  \\\n",
      "0  https://cdn.myanimelist.net/images/anime/4/196...   \n",
      "1  https://cdn.myanimelist.net/images/anime/1439/...   \n",
      "2  https://cdn.myanimelist.net/images/anime/1130/...   \n",
      "3  https://cdn.myanimelist.net/images/anime/10/19...   \n",
      "4  https://cdn.myanimelist.net/images/anime/7/215...   \n",
      "\n",
      "                          images.jpg.small_image_url  \\\n",
      "0  https://cdn.myanimelist.net/images/anime/4/196...   \n",
      "1  https://cdn.myanimelist.net/images/anime/1439/...   \n",
      "2  https://cdn.myanimelist.net/images/anime/1130/...   \n",
      "3  https://cdn.myanimelist.net/images/anime/10/19...   \n",
      "4  https://cdn.myanimelist.net/images/anime/7/215...   \n",
      "\n",
      "                          images.jpg.large_image_url  \\\n",
      "0  https://cdn.myanimelist.net/images/anime/4/196...   \n",
      "1  https://cdn.myanimelist.net/images/anime/1439/...   \n",
      "2  https://cdn.myanimelist.net/images/anime/1130/...   \n",
      "3  https://cdn.myanimelist.net/images/anime/10/19...   \n",
      "4  https://cdn.myanimelist.net/images/anime/7/215...   \n",
      "\n",
      "                               images.webp.image_url  \\\n",
      "0  https://cdn.myanimelist.net/images/anime/4/196...   \n",
      "1  https://cdn.myanimelist.net/images/anime/1439/...   \n",
      "2  https://cdn.myanimelist.net/images/anime/1130/...   \n",
      "3  https://cdn.myanimelist.net/images/anime/10/19...   \n",
      "4  https://cdn.myanimelist.net/images/anime/7/215...   \n",
      "\n",
      "                         images.webp.small_image_url  \\\n",
      "0  https://cdn.myanimelist.net/images/anime/4/196...   \n",
      "1  https://cdn.myanimelist.net/images/anime/1439/...   \n",
      "2  https://cdn.myanimelist.net/images/anime/1130/...   \n",
      "3  https://cdn.myanimelist.net/images/anime/10/19...   \n",
      "4  https://cdn.myanimelist.net/images/anime/7/215...   \n",
      "\n",
      "                         images.webp.large_image_url trailer.youtube_id  \\\n",
      "0  https://cdn.myanimelist.net/images/anime/4/196...        gY5nDXOtv_o   \n",
      "1  https://cdn.myanimelist.net/images/anime/1439/...               None   \n",
      "2  https://cdn.myanimelist.net/images/anime/1130/...        bJVyIXeUznY   \n",
      "3  https://cdn.myanimelist.net/images/anime/10/19...        7UkaILjPk8M   \n",
      "4  https://cdn.myanimelist.net/images/anime/7/215...               None   \n",
      "\n",
      "                                   trailer.url  \\\n",
      "0  https://www.youtube.com/watch?v=gY5nDXOtv_o   \n",
      "1                                         None   \n",
      "2  https://www.youtube.com/watch?v=bJVyIXeUznY   \n",
      "3  https://www.youtube.com/watch?v=7UkaILjPk8M   \n",
      "4                                         None   \n",
      "\n",
      "                                   trailer.embed_url  \\\n",
      "0  https://www.youtube.com/embed/gY5nDXOtv_o?enab...   \n",
      "1                                               None   \n",
      "2  https://www.youtube.com/embed/bJVyIXeUznY?enab...   \n",
      "3  https://www.youtube.com/embed/7UkaILjPk8M?enab...   \n",
      "4                                               None   \n",
      "\n",
      "                            trailer.images.image_url  \\\n",
      "0  https://img.youtube.com/vi/gY5nDXOtv_o/default...   \n",
      "1                                               None   \n",
      "2  https://img.youtube.com/vi/bJVyIXeUznY/default...   \n",
      "3  https://img.youtube.com/vi/7UkaILjPk8M/default...   \n",
      "4                                               None   \n",
      "\n",
      "                      trailer.images.small_image_url  \\\n",
      "0  https://img.youtube.com/vi/gY5nDXOtv_o/sddefau...   \n",
      "1                                               None   \n",
      "2  https://img.youtube.com/vi/bJVyIXeUznY/sddefau...   \n",
      "3  https://img.youtube.com/vi/7UkaILjPk8M/sddefau...   \n",
      "4                                               None   \n",
      "\n",
      "                     trailer.images.medium_image_url  \\\n",
      "0  https://img.youtube.com/vi/gY5nDXOtv_o/mqdefau...   \n",
      "1                                               None   \n",
      "2  https://img.youtube.com/vi/bJVyIXeUznY/mqdefau...   \n",
      "3  https://img.youtube.com/vi/7UkaILjPk8M/mqdefau...   \n",
      "4                                               None   \n",
      "\n",
      "                      trailer.images.large_image_url  \\\n",
      "0  https://img.youtube.com/vi/gY5nDXOtv_o/hqdefau...   \n",
      "1                                               None   \n",
      "2  https://img.youtube.com/vi/bJVyIXeUznY/hqdefau...   \n",
      "3  https://img.youtube.com/vi/7UkaILjPk8M/hqdefau...   \n",
      "4                                               None   \n",
      "\n",
      "                    trailer.images.maximum_image_url  \\\n",
      "0  https://img.youtube.com/vi/gY5nDXOtv_o/maxresd...   \n",
      "1                                               None   \n",
      "2  https://img.youtube.com/vi/bJVyIXeUznY/maxresd...   \n",
      "3  https://img.youtube.com/vi/7UkaILjPk8M/maxresd...   \n",
      "4                                               None   \n",
      "\n",
      "                  aired.from                   aired.to  aired.prop.from.day  \\\n",
      "0  1998-04-03T00:00:00+00:00  1999-04-24T00:00:00+00:00                  3.0   \n",
      "1  2001-09-01T00:00:00+00:00                       None                  1.0   \n",
      "2  1998-04-01T00:00:00+00:00  1998-09-30T00:00:00+00:00                  1.0   \n",
      "3  2002-07-03T00:00:00+00:00  2002-12-25T00:00:00+00:00                  3.0   \n",
      "4  2004-09-30T00:00:00+00:00  2005-09-29T00:00:00+00:00                 30.0   \n",
      "\n",
      "   aired.prop.from.month  aired.prop.from.year  aired.prop.to.day  \\\n",
      "0                    4.0                1998.0               24.0   \n",
      "1                    9.0                2001.0                NaN   \n",
      "2                    4.0                1998.0               30.0   \n",
      "3                    7.0                2002.0               25.0   \n",
      "4                    9.0                2004.0               29.0   \n",
      "\n",
      "   aired.prop.to.month  aired.prop.to.year                  aired.string  \\\n",
      "0                  4.0              1999.0   Apr 3, 1998 to Apr 24, 1999   \n",
      "1                  NaN                 NaN                   Sep 1, 2001   \n",
      "2                  9.0              1998.0   Apr 1, 1998 to Sep 30, 1998   \n",
      "3                 12.0              2002.0   Jul 3, 2002 to Dec 25, 2002   \n",
      "4                  9.0              2005.0  Sep 30, 2004 to Sep 29, 2005   \n",
      "\n",
      "  broadcast.day broadcast.time broadcast.timezone           broadcast.string  \n",
      "0     Saturdays          01:00         Asia/Tokyo   Saturdays at 01:00 (JST)  \n",
      "1          None           None               None                       None  \n",
      "2     Thursdays          01:15         Asia/Tokyo   Thursdays at 01:15 (JST)  \n",
      "3    Wednesdays          01:25         Asia/Tokyo  Wednesdays at 01:25 (JST)  \n",
      "4     Thursdays          18:30         Asia/Tokyo   Thursdays at 18:30 (JST)  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Normalizaci√≥n de Columnas Anidadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para extraer valores de listas de diccionarios\n",
    "def extract_from_list_dict(data, key='name'):\n",
    "    if isinstance(data, list):\n",
    "        return ', '.join([str(d.get(key, '')) for d in data])\n",
    "    return ''\n",
    "\n",
    "# Aplicar a columnas relevantes\n",
    "for col in ['titles', 'producers', 'studios', 'genres', 'themes', 'demographics', 'licensors']:\n",
    "    df[f'{col}_extracted'] = df[col].apply(extract_from_list_dict)\n",
    "\n",
    "# Extraer imagen principal\n",
    "df['main_image'] = df['images.jpg.large_image_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Manejo de Datos Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir fechas a datetime\n",
    "df['aired_from'] = pd.to_datetime(df['aired.from'])\n",
    "df['aired_to'] = pd.to_datetime(df['aired.to'])\n",
    "\n",
    "# Crear columna de d√©cada\n",
    "df['decade'] = (df['aired.prop.from.year']//10)*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Limpieza de Columnas Redundantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versi√≥n segura que maneja tipos y valores nulos\n",
    "df['title_consistency'] = df.apply(\n",
    "    lambda x: (\n",
    "        str(x['title']) in str(x['titles_extracted']).split(', ') \n",
    "        if pd.notna(x['title']) and pd.notna(x['titles_extracted']) \n",
    "        else False\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Alternativa m√°s eficiente (evitando apply)\n",
    "df['title_consistency'] = [\n",
    "    str(title) in titles.split(', ') \n",
    "    for title, titles in zip(df['title'], df['titles_extracted'])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Tratamiento de Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar valores faltantes estrat√©gicamente\n",
    "df['score'] = df['score'].fillna(df.groupby('type')['score'].transform('median'))\n",
    "df['duration'] = df['duration'].fillna('Unknown')\n",
    "df['type'] = df['type'].fillna('Unknown')\n",
    "\n",
    "# Eliminar filas con datos cr√≠ticos faltantes\n",
    "df = df.dropna(subset=['mal_id', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî® Procesando g√©neros y temas...\n",
      "‚úÖ Estructura relacional creada:\n",
      "- genres.csv: 22 g√©neros √∫nicos\n",
      "- themes.csv: 53 temas √∫nicos\n",
      "- licensors.csv: 92 distribuidoras √∫nicos\n",
      "- anime_genres.csv: 46293 relaciones g√©nero-anime\n",
      "- anime_themes.csv: 34289 relaciones tema-anime\n",
      "- anime_licensors.csv: 28404 relaciones distribuidora-anime\n",
      "\n",
      "üíæ Archivos guardados:\n",
      "- animes_clean.csv (datos principales)\n",
      "- genres.csv (tabla de g√©neros √∫nicos)\n",
      "- anime_genres_relation.csv (relaciones anime-g√©nero)\n",
      "\n",
      "‚úÖ Dataset final:\n",
      "‚Ä¢ Dimensiones: 27529 filas x 32 columnas\n",
      "‚Ä¢ Memoria usada: 44.1 MB\n",
      "\n",
      "üìä Columnas principales:\n",
      "   mal_id                            title   type  year  season   time_slot  \\\n",
      "0       1                     Cowboy Bebop     TV  1998  Spring  late_night   \n",
      "1       5  Cowboy Bebop: Tengoku no Tobira  Movie  2001    Fall     unknown   \n",
      "2       6                           Trigun     TV  1998  Spring  late_night   \n",
      "3       7               Witch Hunter Robin     TV  2002  Summer  late_night   \n",
      "4       8                   Bouken Ou Beet     TV  2004    Fall   afternoon   \n",
      "\n",
      "   decade  score    rank  popularity  members  favorites  \n",
      "0  1990.0   8.75    47.0          42  1951449      85799  \n",
      "1  2000.0   8.38   214.0         637   393928       1686  \n",
      "2  1990.0   8.22   367.0         260   795496      16696  \n",
      "3  2000.0   7.24  3174.0        1926   122032        664  \n",
      "4  2000.0   6.93  4698.0        5581    16184         16  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ================= CONFIGURACI√ìN INICIAL =================\n",
    "TIME_SLOTS = {\n",
    "    1: ('morning', (5, 12)),\n",
    "    2: ('midday', (12, 14)),\n",
    "    3: ('afternoon', (14, 19)),\n",
    "    4: ('prime', (19, 23)),\n",
    "    5: ('night', (23, 24)),\n",
    "    6: ('late_night', (0, 5)),\n",
    "    0: ('unknown', (None, None))\n",
    "}\n",
    "\n",
    "# ================= FUNCIONES AUXILIARES =================\n",
    "def get_season_from_date(date):\n",
    "    try:\n",
    "        month = pd.to_datetime(date).month\n",
    "        if 3 <= month <= 5: return 'Spring'\n",
    "        elif 6 <= month <= 8: return 'Summer'\n",
    "        elif 9 <= month <= 11: return 'Fall'\n",
    "        else: return 'Winter'\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_time_slot(time_str):\n",
    "    if pd.isna(time_str): return 'unknown'\n",
    "    try:\n",
    "        hour = int(pd.to_datetime(time_str).hour)\n",
    "        for slot_id, (name, (start, end)) in TIME_SLOTS.items():\n",
    "            if slot_id == 0: continue\n",
    "            if (start <= hour < end) or (name == 'late_night' and (hour >= 0 or hour < 5)):\n",
    "                return name\n",
    "        return 'unknown'\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "def extract_year_from_broadcast(row):\n",
    "    try:\n",
    "        if pd.notna(row['aired_from']):\n",
    "            return pd.to_datetime(row['aired_from']).year\n",
    "        if pd.notna(row.get('broadcast.string')):\n",
    "            years = [int(s) for s in str(row['broadcast.string']).split() if s.isdigit()]\n",
    "            if years: return max(years)\n",
    "        if pd.notna(row.get('aired.prop.from.year')):\n",
    "            return int(row['aired.prop.from.year'])\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# ================= PROCESAMIENTO PRINCIPAL =================\n",
    "# 1. Crear copia segura\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 2. Calcular columnas nuevas\n",
    "df_clean['season'] = df_clean['aired_from'].apply(get_season_from_date)\n",
    "df_clean['time_slot'] = df_clean['broadcast.time'].apply(get_time_slot)\n",
    "df_clean['year_computed'] = df_clean.apply(extract_year_from_broadcast, axis=1)\n",
    "\n",
    "# 3. Consolidar columnas\n",
    "df_clean['season'] = df_clean['season'].astype('category')\n",
    "df_clean['time_slot'] = pd.Categorical(\n",
    "    df_clean['time_slot'],\n",
    "    categories=['morning', 'midday', 'afternoon', 'prime', 'night', 'late_night', 'unknown'],\n",
    "    ordered=True\n",
    ")\n",
    "df_clean['year'] = df_clean['year'].fillna(df_clean['year_computed']).astype('Int32')\n",
    "\n",
    "# 4. Eliminar columnas temporales/intermedias\n",
    "cols_to_drop = [\n",
    "    'season_computed', 'year_computed', \n",
    "    'aired.from', 'aired.to', 'aired.prop.from.day', 'aired.prop.from.month',\n",
    "    'aired.prop.from.year', 'aired.prop.to.day', 'aired.prop.to.month',\n",
    "    'aired.prop.to.year', 'aired.string', 'broadcast.day', 'broadcast.time',\n",
    "    'broadcast.timezone', 'broadcast.string',\n",
    "    # Columnas de im√°genes\n",
    "    'images.jpg.image_url', 'images.jpg.small_image_url', 'images.jpg.large_image_url',\n",
    "    'images.webp.image_url', 'images.webp.small_image_url', 'images.webp.large_image_url',\n",
    "    \n",
    "    # Columnas de t√≠tulos redundantes (conservando solo title y titles_extracted)\n",
    "    'title_english', 'title_japanese', 'titles', 'title_english', 'title_japanese', 'title_synonym',\n",
    "    # Columnas de trailer\n",
    "    'trailer.youtube_id', 'trailer.url', 'trailer.embed_url',\n",
    "    'trailer.images.image_url', 'trailer.images.small_image_url',\n",
    "    'trailer.images.medium_image_url', 'trailer.images.large_image_url',\n",
    "    'trailer.images.maximum_image_url',\n",
    "    \n",
    "    # Columnas anidadas originales (usaremos las versiones _extracted)\n",
    "    'genres', 'themes', 'explicit_genres', 'demographics',\n",
    "    'producers', 'studios', 'licensors'\n",
    "]\n",
    "df_clean = df_clean.drop(columns=[col for col in cols_to_drop if col in df_clean.columns])\n",
    "\n",
    "# 5. Optimizaci√≥n de tipos\n",
    "dtype_map = {\n",
    "    'mal_id': 'uint32',\n",
    "    'episodes': 'uint16',\n",
    "    'score': 'float32',\n",
    "    'rank': 'uint32',\n",
    "    'popularity': 'uint32',\n",
    "    'members': 'uint32',\n",
    "    'favorites': 'uint32',\n",
    "    'decade': 'uint16'\n",
    "}\n",
    "df_clean = df_clean.astype(dtype_map, errors='ignore')\n",
    "\n",
    "# 6. Reordenar columnas\n",
    "first_cols = [\n",
    "    'mal_id', 'title', 'type', 'year',\n",
    "    'season', 'time_slot', 'decade', 'score', 'rank', 'popularity', 'members', 'favorites'\n",
    "]\n",
    "other_cols = [col for col in df_clean.columns if col not in first_cols]\n",
    "df_clean = df_clean[first_cols + other_cols]\n",
    "\n",
    "\n",
    "# ================= NORMALIZACI√ìN DE G√âNEROS =================\n",
    "print(\"\\nüî® Procesando g√©neros y temas...\")\n",
    "\n",
    "# 1. Extraer TODOS los g√©neros √∫nicos\n",
    "all_genres = df_clean['genres_extracted'].str.split(', ').explode().dropna().unique()\n",
    "genres_df = pd.DataFrame({\n",
    "    'genre_id': range(1, len(all_genres)+1),\n",
    "    'genre_name': sorted(all_genres)\n",
    "})\n",
    "\n",
    "# 2. Extraer TODOS los temas √∫nicos\n",
    "all_themes = df_clean['themes_extracted'].str.split(', ').explode().dropna().unique()\n",
    "themes_df = pd.DataFrame({\n",
    "    'theme_id': range(1, len(all_themes)+1),\n",
    "    'theme_name': sorted(all_themes)\n",
    "})\n",
    "\n",
    "all_licensors = df_clean['licensors_extracted'].str.split(', ').explode().dropna().unique()\n",
    "licensors_df = pd.DataFrame({\n",
    "    'licensor_id': range(1, len(all_licensors)+1),\n",
    "    'licensor_name': sorted(all_licensors)\n",
    "})\n",
    "\n",
    "# 3. Crear tabla de relaci√≥n anime-g√©nero\n",
    "genre_relations = []\n",
    "for _, row in df_clean.iterrows():\n",
    "    if pd.notna(row['genres_extracted']):\n",
    "        for genre in row['genres_extracted'].split(', '):\n",
    "            genre_id = genres_df[genres_df['genre_name'] == genre]['genre_id'].values[0]\n",
    "            genre_relations.append({'mal_id': row['mal_id'], 'genre_id': genre_id})\n",
    "\n",
    "anime_genres_df = pd.DataFrame(genre_relations)\n",
    "\n",
    "# 4. Crear tabla de relaci√≥n anime-tema\n",
    "theme_relations = []\n",
    "for _, row in df_clean.iterrows():\n",
    "    if pd.notna(row['themes_extracted']):\n",
    "        for theme in row['themes_extracted'].split(', '):\n",
    "            theme_id = themes_df[themes_df['theme_name'] == theme]['theme_id'].values[0]\n",
    "            theme_relations.append({'mal_id': row['mal_id'], 'theme_id': theme_id})\n",
    "\n",
    "anime_themes_df = pd.DataFrame(theme_relations)\n",
    "\n",
    "# 5. Crear tabla de relaci√≥n anime-licensor (CORREGIDO)\n",
    "licensors_relations = []\n",
    "for _, row in df_clean.iterrows():\n",
    "    if pd.notna(row['licensors_extracted']):\n",
    "        for licensor in row['licensors_extracted'].split(', '):\n",
    "            licensor_ids = licensors_df[licensors_df['licensor_name'] == licensor]['licensor_id'].values\n",
    "            if len(licensor_ids) > 0:\n",
    "                licensor_id = licensor_ids[0]\n",
    "                licensors_relations.append({'mal_id': row['mal_id'], 'licensor_id': licensor_id})\n",
    "            else:\n",
    "                print(f\"Advertencia: No se encontr√≥ el distribuidor '{licensor}' en licensors_df.\")\n",
    "\n",
    "anime_licensors_df = pd.DataFrame(licensors_relations)\n",
    "\n",
    "# 6. Eliminar columnas originales (ya no necesarias)\n",
    "df_clean = df_clean.drop(columns=['genres_extracted', 'themes_extracted', 'licensors_extracted'])\n",
    "\n",
    "# 7. Guardar las tablas\n",
    "genres_df.to_csv('genres.csv', index=False)\n",
    "themes_df.to_csv('themes.csv', index=False)\n",
    "licensors_df.to_csv('licensors.csv', index=False)\n",
    "anime_genres_df.to_csv('anime_genres.csv', index=False)\n",
    "anime_themes_df.to_csv('anime_themes.csv', index=False)\n",
    "anime_licensors_df.to_csv('anime_licensors.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Estructura relacional creada:\")\n",
    "print(f\"- genres.csv: {len(genres_df)} g√©neros √∫nicos\")\n",
    "print(f\"- themes.csv: {len(themes_df)} temas √∫nicos\")\n",
    "print(f\"- licensors.csv: {len(licensors_df)} distribuidoras √∫nicos\")\n",
    "print(f\"- anime_genres.csv: {len(anime_genres_df)} relaciones g√©nero-anime\")\n",
    "print(f\"- anime_themes.csv: {len(anime_themes_df)} relaciones tema-anime\")\n",
    "print(f\"- anime_licensors.csv: {len(anime_licensors_df)} relaciones distribuidora-anime\")\n",
    "\n",
    "# ================= VERIFICACI√ìN FINAL =================\n",
    "# Guardar el archivo principal\n",
    "df_clean.to_csv('animes_clean.csv', index=False)\n",
    "print(\"\\nüíæ Archivos guardados:\")\n",
    "print(\"- animes_clean.csv (datos principales)\")\n",
    "print(\"- genres.csv (tabla de g√©neros √∫nicos)\")\n",
    "print(\"- anime_genres_relation.csv (relaciones anime-g√©nero)\")\n",
    "# ================= VERIFICACI√ìN =================\n",
    "print(\"\\n‚úÖ Dataset final:\")\n",
    "print(f\"‚Ä¢ Dimensiones: {df_clean.shape[0]} filas x {df_clean.shape[1]} columnas\")\n",
    "print(f\"‚Ä¢ Memoria usada: {df_clean.memory_usage(deep=True).sum()/1024**2:.1f} MB\")\n",
    "print(\"\\nüìä Columnas principales:\")\n",
    "print(df_clean[first_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî® Procesando g√©neros y temas...\n",
      "‚úÖ Estructura relacional creada:\n",
      "- genres.csv: 22 g√©neros √∫nicos\n",
      "- themes.csv: 53 temas √∫nicos\n",
      "- licensors.csv: 92 distribuidoras √∫nicos\n",
      "- anime_genres.csv: 46293 relaciones g√©nero-anime\n",
      "- anime_themes.csv: 34289 relaciones tema-anime\n",
      "- anime_licensors.csv: 28404 relaciones distribuidora-anime\n",
      "\n",
      "üíæ Archivos guardados:\n",
      "- animes_clean.csv (datos principales)\n",
      "- genres.csv (tabla de g√©neros √∫nicos)\n",
      "- anime_genres_relation.csv (relaciones anime-g√©nero)\n",
      "\n",
      "‚úÖ Dataset final:\n",
      "‚Ä¢ Dimensiones: 27529 filas x 32 columnas\n",
      "‚Ä¢ Memoria usada: 44.1 MB\n",
      "\n",
      "üìä Columnas principales:\n",
      "   mal_id                            title   type  year  season   time_slot  \\\n",
      "0       1                     Cowboy Bebop     TV  1998  Spring  late_night   \n",
      "1       5  Cowboy Bebop: Tengoku no Tobira  Movie  2001    Fall     unknown   \n",
      "2       6                           Trigun     TV  1998  Spring  late_night   \n",
      "3       7               Witch Hunter Robin     TV  2002  Summer  late_night   \n",
      "4       8                   Bouken Ou Beet     TV  2004    Fall   afternoon   \n",
      "\n",
      "   decade  score    rank  popularity  members  favorites  \n",
      "0  1990.0   8.75    47.0          42  1951449      85799  \n",
      "1  2000.0   8.38   214.0         637   393928       1686  \n",
      "2  1990.0   8.22   367.0         260   795496      16696  \n",
      "3  2000.0   7.24  3174.0        1926   122032        664  \n",
      "4  2000.0   6.93  4698.0        5581    16184         16  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ================= CONFIGURACI√ìN INICIAL =================\n",
    "TIME_SLOTS = {\n",
    "    1: ('morning', (5, 12)),\n",
    "    2: ('midday', (12, 14)),\n",
    "    3: ('afternoon', (14, 19)),\n",
    "    4: ('prime', (19, 23)),\n",
    "    5: ('night', (23, 24)),\n",
    "    6: ('late_night', (0, 5)),\n",
    "    0: ('unknown', (None, None))\n",
    "}\n",
    "\n",
    "# ================= FUNCIONES AUXILIARES =================\n",
    "def get_season_from_date(date):\n",
    "    try:\n",
    "        month = pd.to_datetime(date).month\n",
    "        if 3 <= month <= 5: return 'Spring'\n",
    "        elif 6 <= month <= 8: return 'Summer'\n",
    "        elif 9 <= month <= 11: return 'Fall'\n",
    "        else: return 'Winter'\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_time_slot(time_str):\n",
    "    if pd.isna(time_str): return 'unknown'\n",
    "    try:\n",
    "        hour = int(pd.to_datetime(time_str).hour)\n",
    "        for slot_id, (name, (start, end)) in TIME_SLOTS.items():\n",
    "            if slot_id == 0: continue\n",
    "            if (start <= hour < end) or (name == 'late_night' and (hour >= 0 or hour < 5)):\n",
    "                return name\n",
    "        return 'unknown'\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "def extract_year_from_broadcast(row):\n",
    "    try:\n",
    "        if pd.notna(row['aired_from']):\n",
    "            return pd.to_datetime(row['aired_from']).year\n",
    "        if pd.notna(row.get('broadcast.string')):\n",
    "            years = [int(s) for s in str(row['broadcast.string']).split() if s.isdigit()]\n",
    "            if years: return max(years)\n",
    "        if pd.notna(row.get('aired.prop.from.year')):\n",
    "            return int(row['aired.prop.from.year'])\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# ================= PROCESAMIENTO PRINCIPAL =================\n",
    "# 1. Crear copia segura\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 2. Calcular columnas nuevas\n",
    "df_clean['season'] = df_clean['aired_from'].apply(get_season_from_date)\n",
    "df_clean['time_slot'] = df_clean['broadcast.time'].apply(get_time_slot)\n",
    "df_clean['year_computed'] = df_clean.apply(extract_year_from_broadcast, axis=1)\n",
    "\n",
    "# 3. Consolidar columnas\n",
    "df_clean['season'] = df_clean['season'].astype('category')\n",
    "df_clean['time_slot'] = pd.Categorical(\n",
    "    df_clean['time_slot'],\n",
    "    categories=['morning', 'midday', 'afternoon', 'prime', 'night', 'late_night', 'unknown'],\n",
    "    ordered=True\n",
    ")\n",
    "df_clean['year'] = df_clean['year'].fillna(df_clean['year_computed']).astype('Int32')\n",
    "\n",
    "# 4. Eliminar columnas temporales/intermedias\n",
    "cols_to_drop = [\n",
    "    'season_computed', 'year_computed', \n",
    "    'aired.from', 'aired.to', 'aired.prop.from.day', 'aired.prop.from.month',\n",
    "    'aired.prop.from.year', 'aired.prop.to.day', 'aired.prop.to.month',\n",
    "    'aired.prop.to.year', 'aired.string', 'broadcast.day', 'broadcast.time',\n",
    "    'broadcast.timezone', 'broadcast.string',\n",
    "    # Columnas de im√°genes\n",
    "    'images.jpg.image_url', 'images.jpg.small_image_url', 'images.jpg.large_image_url',\n",
    "    'images.webp.image_url', 'images.webp.small_image_url', 'images.webp.large_image_url',\n",
    "    \n",
    "    # Columnas de t√≠tulos redundantes (conservando solo title y titles_extracted)\n",
    "    'title_english', 'title_japanese', 'titles', 'title_english', 'title_japanese', 'title_synonym',\n",
    "    # Columnas de trailer\n",
    "    'trailer.youtube_id', 'trailer.url', 'trailer.embed_url',\n",
    "    'trailer.images.image_url', 'trailer.images.small_image_url',\n",
    "    'trailer.images.medium_image_url', 'trailer.images.large_image_url',\n",
    "    'trailer.images.maximum_image_url',\n",
    "    \n",
    "    # Columnas anidadas originales (usaremos las versiones _extracted)\n",
    "    'genres', 'themes', 'explicit_genres', 'demographics',\n",
    "    'producers', 'studios', 'licensors'\n",
    "]\n",
    "df_clean = df_clean.drop(columns=[col for col in cols_to_drop if col in df_clean.columns])\n",
    "\n",
    "# 5. Optimizaci√≥n de tipos\n",
    "dtype_map = {\n",
    "    'mal_id': 'uint32',\n",
    "    'episodes': 'uint16',\n",
    "    'score': 'float32',\n",
    "    'rank': 'uint32',\n",
    "    'popularity': 'uint32',\n",
    "    'members': 'uint32',\n",
    "    'favorites': 'uint32',\n",
    "    'decade': 'uint16'\n",
    "}\n",
    "df_clean = df_clean.astype(dtype_map, errors='ignore')\n",
    "\n",
    "# 6. Reordenar columnas\n",
    "first_cols = [\n",
    "    'mal_id', 'title', 'type', 'year',\n",
    "    'season', 'time_slot', 'decade', 'score', 'rank', 'popularity', 'members', 'favorites'\n",
    "]\n",
    "other_cols = [col for col in df_clean.columns if col not in first_cols]\n",
    "df_clean = df_clean[first_cols + other_cols]\n",
    "\n",
    "\n",
    "# ================= NORMALIZACI√ìN DE G√âNEROS =================\n",
    "print(\"\\nüî® Procesando g√©neros y temas...\")\n",
    "\n",
    "# 1. Extraer TODOS los g√©neros √∫nicos\n",
    "all_genres = df_clean['genres_extracted'].str.split(', ').explode().dropna().unique()\n",
    "genres_df = pd.DataFrame({\n",
    "    'genre_id': range(1, len(all_genres)+1),\n",
    "    'genre_name': sorted(all_genres)\n",
    "})\n",
    "\n",
    "# 2. Extraer TODOS los temas √∫nicos\n",
    "all_themes = df_clean['themes_extracted'].str.split(', ').explode().dropna().unique()\n",
    "themes_df = pd.DataFrame({\n",
    "    'theme_id': range(1, len(all_themes)+1),\n",
    "    'theme_name': sorted(all_themes)\n",
    "})\n",
    "\n",
    "all_licensors = df_clean['licensors_extracted'].str.split(', ').explode().dropna().unique()\n",
    "licensors_df = pd.DataFrame({\n",
    "    'licensor_id': range(1, len(all_licensors)+1),\n",
    "    'licensor_name': sorted(all_licensors)\n",
    "})\n",
    "\n",
    "# 3. Crear tabla de relaci√≥n anime-g√©nero\n",
    "genre_relations = []\n",
    "for _, row in df_clean.iterrows():\n",
    "    if pd.notna(row['genres_extracted']):\n",
    "        for genre in row['genres_extracted'].split(', '):\n",
    "            genre_id = genres_df[genres_df['genre_name'] == genre]['genre_id'].values[0]\n",
    "            genre_relations.append({'mal_id': row['mal_id'], 'genre_id': genre_id})\n",
    "\n",
    "anime_genres_df = pd.DataFrame(genre_relations)\n",
    "\n",
    "# 4. Crear tabla de relaci√≥n anime-tema\n",
    "theme_relations = []\n",
    "for _, row in df_clean.iterrows():\n",
    "    if pd.notna(row['themes_extracted']):\n",
    "        for theme in row['themes_extracted'].split(', '):\n",
    "            theme_id = themes_df[themes_df['theme_name'] == theme]['theme_id'].values[0]\n",
    "            theme_relations.append({'mal_id': row['mal_id'], 'theme_id': theme_id})\n",
    "\n",
    "anime_themes_df = pd.DataFrame(theme_relations)\n",
    "\n",
    "# 5. Crear tabla de relaci√≥n anime-licensor (CORREGIDO Y MEJORADO)\n",
    "licensors_relations = []\n",
    "for _, row in df_clean.iterrows():\n",
    "    if pd.notna(row['licensors_extracted']):\n",
    "        for licensor in row['licensors_extracted'].split(', '):\n",
    "            licensor_ids = licensors_df[licensors_df['licensor_name'] == licensor]['licensor_id'].values\n",
    "            if len(licensor_ids) > 0:\n",
    "                licensor_id = licensor_ids[0]\n",
    "                licensors_relations.append({'mal_id': row['mal_id'], 'licensor_id': licensor_id})\n",
    "            else:\n",
    "                print(f\"Advertencia: No se encontr√≥ el distribuidor '{licensor}' en licensors_df para mal_id: {row['mal_id']}. Posibles errores de normalizaci√≥n.\")\n",
    "                # Opcional: Puedes decidir asignar un valor predeterminado o omitir la relaci√≥n.\n",
    "                # Ejemplo: licensors_relations.append({'mal_id': row['mal_id'], 'licensor_id': None})\n",
    "\n",
    "anime_licensors_df = pd.DataFrame(licensors_relations)\n",
    "\n",
    "# 6. Eliminar columnas originales (ya no necesarias)\n",
    "df_clean = df_clean.drop(columns=['genres_extracted', 'themes_extracted', 'licensors_extracted'])\n",
    "\n",
    "# 7. Guardar las tablas\n",
    "genres_df.to_csv('genres.csv', index=False)\n",
    "themes_df.to_csv('themes.csv', index=False)\n",
    "licensors_df.to_csv('licensors.csv', index=False)\n",
    "anime_genres_df.to_csv('anime_genres.csv', index=False)\n",
    "anime_themes_df.to_csv('anime_themes.csv', index=False)\n",
    "anime_licensors_df.to_csv('anime_licensors.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Estructura relacional creada:\")\n",
    "print(f\"- genres.csv: {len(genres_df)} g√©neros √∫nicos\")\n",
    "print(f\"- themes.csv: {len(themes_df)} temas √∫nicos\")\n",
    "print(f\"- licensors.csv: {len(licensors_df)} distribuidoras √∫nicos\")\n",
    "print(f\"- anime_genres.csv: {len(anime_genres_df)} relaciones g√©nero-anime\")\n",
    "print(f\"- anime_themes.csv: {len(anime_themes_df)} relaciones tema-anime\")\n",
    "print(f\"- anime_licensors.csv: {len(anime_licensors_df)} relaciones distribuidora-anime\")\n",
    "\n",
    "# ================= VERIFICACI√ìN FINAL =================\n",
    "# Guardar el archivo principal\n",
    "df_clean.to_csv('animes_clean.csv', index=False)\n",
    "print(\"\\nüíæ Archivos guardados:\")\n",
    "print(\"- animes_clean.csv (datos principales)\")\n",
    "print(\"- genres.csv (tabla de g√©neros √∫nicos)\")\n",
    "print(\"- anime_genres_relation.csv (relaciones anime-g√©nero)\")\n",
    "# ================= VERIFICACI√ìN =================\n",
    "print(\"\\n‚úÖ Dataset final:\")\n",
    "print(f\"‚Ä¢ Dimensiones: {df_clean.shape[0]} filas x {df_clean.shape[1]} columnas\")\n",
    "print(f\"‚Ä¢ Memoria usada: {df_clean.memory_usage(deep=True).sum()/1024**2:.1f} MB\")\n",
    "print(\"\\nüìä Columnas principales:\")\n",
    "print(df_clean[first_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 27529 entries, 0 to 27529\n",
      "Data columns (total 32 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   mal_id                  27529 non-null  uint32             \n",
      " 1   title                   27529 non-null  object             \n",
      " 2   type                    27529 non-null  object             \n",
      " 3   year                    26685 non-null  Int32              \n",
      " 4   season                  27529 non-null  category           \n",
      " 5   time_slot               27529 non-null  category           \n",
      " 6   decade                  26685 non-null  float64            \n",
      " 7   score                   27446 non-null  float32            \n",
      " 8   rank                    21127 non-null  float64            \n",
      " 9   popularity              27529 non-null  uint32             \n",
      " 10  members                 27529 non-null  uint32             \n",
      " 11  favorites               27529 non-null  uint32             \n",
      " 12  url                     27529 non-null  object             \n",
      " 13  approved                27529 non-null  object             \n",
      " 14  title_synonyms          27529 non-null  object             \n",
      " 15  source                  27529 non-null  object             \n",
      " 16  episodes                26874 non-null  float64            \n",
      " 17  status                  27529 non-null  object             \n",
      " 18  airing                  27529 non-null  object             \n",
      " 19  duration                27529 non-null  object             \n",
      " 20  rating                  26885 non-null  object             \n",
      " 21  scored_by               17576 non-null  float64            \n",
      " 22  synopsis                22702 non-null  object             \n",
      " 23  background              27529 non-null  object             \n",
      " 24  titles_extracted        27529 non-null  object             \n",
      " 25  producers_extracted     27529 non-null  object             \n",
      " 26  studios_extracted       27529 non-null  object             \n",
      " 27  demographics_extracted  27529 non-null  object             \n",
      " 28  main_image              27529 non-null  object             \n",
      " 29  aired_from              26685 non-null  datetime64[ns, UTC]\n",
      " 30  aired_to                10492 non-null  datetime64[ns, UTC]\n",
      " 31  title_consistency       27529 non-null  bool               \n",
      "dtypes: Int32(1), bool(1), category(2), datetime64[ns, UTC](2), float32(1), float64(4), object(17), uint32(4)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Archivo guardado en: myanimelist_tableau_ready.csv\n",
      "Dimensiones finales: 27529 filas x 21 columnas\n",
      "\n",
      "Vista previa de las primeras filas:\n",
      "   mal_id                            title   type  year  season   time_slot  \\\n",
      "0       1                     Cowboy Bebop     TV  1998  Spring  late_night   \n",
      "1       5  Cowboy Bebop: Tengoku no Tobira  Movie  2001    Fall     unknown   \n",
      "2       6                           Trigun     TV  1998  Spring  late_night   \n",
      "\n",
      "   decade  score   rank  popularity  members  favorites  episodes  \\\n",
      "0  1990.0   8.75   47.0          42  1951449      85799      26.0   \n",
      "1  2000.0   8.38  214.0         637   393928       1686       1.0   \n",
      "2  1990.0   8.22  367.0         260   795496      16696      26.0   \n",
      "\n",
      "            status       duration                          rating  \\\n",
      "0  Finished Airing  24 min per ep  R - 17+ (violence & profanity)   \n",
      "1  Finished Airing    1 hr 55 min  R - 17+ (violence & profanity)   \n",
      "2  Finished Airing  24 min per ep       PG-13 - Teens 13 or older   \n",
      "\n",
      "  studios_extracted demographics_extracted  \\\n",
      "0           Sunrise                          \n",
      "1             Bones                          \n",
      "2          Madhouse                Shounen   \n",
      "\n",
      "                                            synopsis  aired_from    aired_to  \n",
      "0  Crime is timeless. By the year 2071, humanity ...  1998-04-03  1999-04-24  \n",
      "1  Another day, another bounty‚Äîsuch is the life o...  2001-09-01         NaN  \n",
      "2  Vash the Stampede is the man with a $$60,000,0...  1998-04-01  1998-09-30  \n"
     ]
    }
   ],
   "source": [
    "# 1. Selecci√≥n final de columnas para Tableau\n",
    "tableau_cols = [\n",
    "    'mal_id', 'title', 'type', 'year', 'season', 'time_slot', 'decade',\n",
    "    'score', 'rank', 'popularity', 'members', 'favorites',\n",
    "    'episodes', 'status', 'duration', 'rating',\n",
    "    'genres_extracted', 'themes_extracted', 'studios_extracted','demographics_extracted', 'licensors_extracted',\n",
    "    'synopsis', 'aired_from', 'aired_to', \n",
    "    ]\n",
    "\n",
    "# 2. Filtrar solo las columnas que existen\n",
    "existing_cols = [col for col in tableau_cols if col in df_clean.columns]\n",
    "df_tableau = df_clean[existing_cols]\n",
    "\n",
    "# 3. Limpieza final para Tableau\n",
    "df_tableau = df_tableau.assign(\n",
    "    # Asegurar fechas en formato Tableau\n",
    "    aired_from = pd.to_datetime(df_tableau['aired_from']).dt.strftime('%Y-%m-%d'),\n",
    "    aired_to = pd.to_datetime(df_tableau['aired_to']).dt.strftime('%Y-%m-%d'),\n",
    "    \n",
    "    # Limpiar sinopsis (eliminar saltos de l√≠nea)\n",
    "    synopsis = df_tableau['synopsis'].str.replace('\\n', ' ').str.replace('\\s+', ' ', regex=True)\n",
    ")\n",
    "\n",
    "# 4. Guardar en CSV optimizado para Tableau\n",
    "output_path = 'myanimelist_tableau_ready.csv'\n",
    "df_tableau.to_csv(\n",
    "    output_path,\n",
    "    index=False,\n",
    "    encoding='utf-8',\n",
    "    date_format='%Y-%m-%d'  # Formato est√°ndar que Tableau reconoce autom√°ticamente\n",
    ")\n",
    "\n",
    "# 5. Verificaci√≥n final\n",
    "print(f\"\\n‚úÖ Archivo guardado en: {output_path}\")\n",
    "print(f\"Dimensiones finales: {df_tableau.shape[0]} filas x {df_tableau.shape[1]} columnas\")\n",
    "print(\"\\nVista previa de las primeras filas:\")\n",
    "print(df_tableau.head(3))\n",
    "\n",
    "# Opcional: Guardar tambi√©n en Excel (mejor manejo de tipos de datos)\n",
    "if 'openpyxl' in sys.modules:\n",
    "    excel_path = 'myanimelist_tableau_ready.xlsx'\n",
    "    df_tableau.to_excel(excel_path, index=False)\n",
    "    print(f\"\\nVersi√≥n Excel guardada en: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
